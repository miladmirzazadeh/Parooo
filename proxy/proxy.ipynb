{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 33808.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http 209.45.61.108:3128\n",
      "https 163.172.136.226:8811\n",
      "http 36.67.218.105:53281\n",
      "https 118.172.181.147:34388\n",
      "http 134.122.103.6:1234\n",
      "https 144.217.101.242:3129\n",
      "http 212.220.216.70:8080\n",
      "https 45.175.139.89:999\n",
      "http 95.179.185.213:3128\n",
      "http 199.188.93.202:8000\n",
      "http 167.71.5.83:8080\n",
      "http 191.232.233.45:3128\n",
      "http 46.34.175.224:8080\n",
      "http 104.244.77.254:8080\n",
      "http 89.28.197.124:8080\n",
      "http 196.223.162.226:80\n",
      "http 177.73.51.7:8080\n",
      "https 116.197.131.26:8080\n",
      "http 51.158.99.51:8811\n",
      "http 46.35.184.187:61003\n",
      "http 159.203.44.177:3128\n",
      "http 200.89.174.104:8080\n",
      "https 199.195.248.24:8080\n",
      "http 37.59.61.18:8080\n",
      "http 37.192.194.50:50165\n",
      "http 104.131.14.247:80\n",
      "http 36.55.226.137:3128\n",
      "http 193.160.214.29:3169\n",
      "https 116.197.131.28:8080\n",
      "http 51.158.68.133:8811\n",
      "http 58.220.95.91:9443\n",
      "https 51.158.68.26:8811\n",
      "https 118.27.15.118:3128\n",
      "https 101.109.255.97:44351\n",
      "https 103.226.49.114:8080\n",
      "https 113.23.138.155:8989\n",
      "http 116.197.131.26:8080\n",
      "http 88.198.50.103:8080\n",
      "https 5.160.150.68:8080\n",
      "http 36.55.226.146:3128\n",
      "http 185.134.23.198:80\n",
      "https 51.158.172.165:8811\n",
      "https 181.129.98.146:8080\n",
      "http 87.98.162.128:80\n",
      "http 51.255.103.170:3129\n",
      "http 54.38.79.183:3128\n",
      "http 46.101.116.200:80\n",
      "http 88.198.24.108:8080\n",
      "http 150.66.1.137:80\n",
      "http 58.220.95.35:10378\n",
      "http 77.66.203.114:33097\n",
      "http 92.222.180.156:8080\n",
      "http 120.132.52.27:8888\n",
      "http 178.215.160.76:8080\n",
      "http 201.159.17.200:8080\n",
      "http 120.132.52.219:8888\n",
      "http 201.159.17.200:8080\n",
      "http 188.170.233.111:3128\n",
      "http 198.211.124.13:80\n",
      "http 144.217.101.242:3129\n",
      "http 52.179.231.206:80\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import tracemalloc\n",
    "from loguru import logger\n",
    "from tqdm import tqdm, trange\n",
    "from random import randint, choice\n",
    "from proxy_client import ProxyProvider\n",
    "from requests_html import AsyncHTMLSession\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "def setup_logger(file_name):\n",
    "    logger.remove()\n",
    "    logger.add(f\"./logs/{file_name}-debug.log\", format=\"{time} {level} {message}\", level=\"DEBUG\", enqueue=True)\n",
    "    logger.add(f\"./logs/{file_name}-info.log\", format=\"{time} {level} {message}\", level=\"INFO\", enqueue=True, backtrace=True)\n",
    "    logger.add(f\"./logs/{file_name}-error.log\", format=\"{time} {level} {message}\", level=\"ERROR\", enqueue=True, backtrace=True, diagnose=True)\n",
    "\n",
    "setup_logger(\"proxy-refine\")\n",
    "\n",
    "\n",
    "proxy_provider = ProxyProvider()\n",
    "asession = AsyncHTMLSession()\n",
    "urls = [\n",
    "    \"https://divar.ir/s/tehran/jobs\",\n",
    "    \"https://instagram.com\", \n",
    "    \"https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\"\n",
    "    \"https://www.tse.ir\",\n",
    "    \"http://tsetmc.ir\",\n",
    "    \"http://tsetmc.ir/Loader.aspx?ParTree=15\",\n",
    "    \"http://www.fipiran.com\",\n",
    "]\n",
    "# urls = [\"https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\", \"https://balad.ir\", \n",
    "#         \"https://google.com\", \"https://youtube.com\", \"https://facebook.com\", \"https://baidu.com\",\n",
    "#         \"https://wikipedia.org\", \"https://twitter.com\", \"https://yahoo.com\", \"https://instagram.com\",\n",
    "#         \"https://amazon.com\"]\n",
    "async def getit(proxy_provider):\n",
    "    i = 0\n",
    "    while i < 100000:\n",
    "        logger.debug(f\"starting {i}\")\n",
    "        i += 1\n",
    "        try:\n",
    "            url = choice(urls)\n",
    "            protocol = url.split(\"://\")[0]\n",
    "            if i % 5 == 0:\n",
    "                p = proxy_provider.get_proxy(protocol)\n",
    "            else:\n",
    "                p = proxy_provider.get_bad_proxy(protocol)\n",
    "            if p == None or p == \"None\":\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            r = await asession.get(f\"{protocol}://google.com\", proxies={protocol: p}, timeout=15)\n",
    "            if \"google.com\" in r.text:\n",
    "                r = await asession.get(url, proxies={protocol: p}, timeout=15)\n",
    "                print(protocol, p)\n",
    "                if r.status_code == 403:\n",
    "                    proxy_provider.bad_ip(protocol, p)\n",
    "            else:\n",
    "                proxy_provider.bad_ip(protocol, p)\n",
    "            del p\n",
    "            del r\n",
    "        except:\n",
    "            proxy_provider.bad_ip(protocol, p)\n",
    "            del p\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for i in trange(50):\n",
    "    tasks.append(getit(proxy_provider))\n",
    "results = await asyncio.wait(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:00<00:00, 83715.09it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1794.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from time import gmtime, strftime, sleep\n",
    "from tqdm import trange, tqdm\n",
    "import time\n",
    "import asyncio\n",
    "import tracemalloc\n",
    "from loguru import logger\n",
    "from tqdm import tqdm, trange\n",
    "from random import randint, choice\n",
    "from proxy_client import ProxyProvider\n",
    "from requests_html import AsyncHTMLSession\n",
    "tracemalloc.start()\n",
    "\n",
    "urls = []\n",
    "with open(\"proxy_url.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        urls.append(line[:-1])\n",
    "\n",
    "def setup_logger(file_name):\n",
    "    logger.remove()\n",
    "    logger.add(f\"./logs/{file_name}-debug.log\", format=\"{time} {level} {message}\", level=\"DEBUG\", enqueue=True)\n",
    "    logger.add(f\"./logs/{file_name}-info.log\", format=\"{time} {level} {message}\", level=\"INFO\", enqueue=True, backtrace=True)\n",
    "    logger.add(f\"./logs/{file_name}-error.log\", format=\"{time} {level} {message}\", level=\"ERROR\", enqueue=True, backtrace=True, diagnose=True)\n",
    "\n",
    "setup_logger(\"proxy\")\n",
    "\n",
    "\n",
    "asession = AsyncHTMLSession()\n",
    "q_url = asyncio.Queue()\n",
    "q_goods = asyncio.Queue()\n",
    "q_proxies = asyncio.Queue()\n",
    "for url in tqdm(urls):\n",
    "    await q_url.put(url)\n",
    "\n",
    "\n",
    "async def getit(q_url, q_goods, q_proxies):\n",
    "    while not q_url.empty():\n",
    "        url = await q_url.get()\n",
    "        logger.debug(f\"start {url}\")\n",
    "        try:\n",
    "            resp = await asession.get(url, timeout=15)\n",
    "            regs = re.findall(r'((?:\\d{1,3}\\.){3}\\d{1,3}):(\\d+)', resp.text)\n",
    "            for reg in regs:\n",
    "                await q_proxies.put(reg[0] + \":\" + reg[1])\n",
    "            await q_goods.put(url)\n",
    "            logger.info(f\"done url {url}\")\n",
    "        except:\n",
    "            logger.debug(f\"bad url {url}\")\n",
    "        q_url.task_done()\n",
    "        \n",
    "\n",
    "tasks = []\n",
    "for i in trange(50):\n",
    "    logger.info(\"start runner\")\n",
    "    tasks.append(getit(q_url, q_goods, q_proxies))\n",
    "results = await asyncio.wait(tasks)\n",
    "\n",
    "proxies = []\n",
    "while not q_proxies.empty():\n",
    "    p = await q_proxies.get()\n",
    "    proxies.append(p)\n",
    "    \n",
    "goods = []\n",
    "while not q_goods.empty():\n",
    "    g = await q_goods.get()\n",
    "    goods.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
